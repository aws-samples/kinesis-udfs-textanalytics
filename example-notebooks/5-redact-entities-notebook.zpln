{
  "paragraphs": [
    {
      "title": "#1 : Create view for entity redaction using UDF",
      "text": "%flink.ssql(type=update)\n\nDROP VIEW IF EXISTS redact_entities_view;\n\nCREATE VIEW  \n    redact_entities_view\nAS\n    SELECT\n        review_id,\n        review_date,\n        review_body,\n        text_analytics_udf(\n            'redact_entities', \n            review_body, \n            review_body_detected_language\n        ) AS redacted_entities\n    FROM\n        amazon_reviews_enriched\n;\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-27T07:39:26+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "View has been dropped.\nView has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1635317245766_1169289663",
      "id": "paragraph_1634849154077_1312654756",
      "dateCreated": "2021-10-27T06:47:25+0000",
      "dateStarted": "2021-10-27T07:36:18+0000",
      "dateFinished": "2021-10-27T07:36:26+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:2799"
    },
    {
      "title": " #2 : Preview redacted entities",
      "text": "%flink.ssql(type=update)\n\nSELECT \n    *\nFROM\n    redact_entities_view\nORDER BY\n    review_id\nLIMIT\n    10\n;",
      "user": "anonymous",
      "dateUpdated": "2021-10-27T07:41:07+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "review_id": "string",
                      "review_date": "string",
                      "review_body": "string",
                      "redacted_pii_entities": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TABLE",
            "data": "review_id\treview_date\treview_body\tredacted_entities\nR100ABAUWTYA1\t2015-08-27\tI have been using these for over a year now. Some days I can take 19 pills so I went with the large and everything fits perfect.  I'm buying the small for the couple pills I have to take in the mornings.<br /><br />It is constructed of a very hard plastic that is quite sturdy.  I think the reviews that complained about cracked threads didn't line up the threads right and forced it. Every couple of months I dab a tiny bit of Vaseline on the threads to keep them screwing smoothly.<br /><br />If you found this review helpful, please let me know by clucking &#34;Yes&#34;.  Than you!\t[I have been using these for [QUANTITY] now. Some days I can take [QUANTITY] so I went with the large and everything fits perfect.  I'm buying the small for the [QUANTITY] I have to take in the mornings.<br /><br />It is constructed of a very hard plastic that is quite sturdy.  I think the reviews that complained about cracked threads didn't line up the threads right and forced it. Every [QUANTITY] I dab a tiny bit of Vaseline on the threads to keep them screwing smoothly.<br /><br />If you found this review helpful, please let me know by clucking &#[OTHER];Yes&#[OTHER];.  Than you!]\nR104YIANJHT42\t2015-08-27\tAwesome product\t[Awesome product]\nR10A3K5CBUSZS8\t2015-08-26\tThis thing is fantastic. I was fully expecting to return it. It helps a lot, and is designed in a manner to put pressure extremely easily on hard to reach spots. The nubs are placed in a very smart manner and fit perfectly in the areas they are aimed for. Thank you.\t[This thing is fantastic. I was fully expecting to return it. It helps a lot, and is designed in a manner to put pressure extremely easily on hard to reach spots. The nubs are placed in a very smart manner and fit perfectly in the areas they are aimed for. Thank you.]\nR10BWJIZZEBJED\t2015-08-31\tMy wife s grabbed these at a store last week, and has been delighted with them. They are quite sturdy and comfortable, so her toes stay apart while painting them but, at the same time, causing no discomfort at all.<br />She s quite happy with them so far, and plans to buy another pair for her sister as a gift.\t[My wife s grabbed these at a store [DATE], and has been delighted with them. They are quite sturdy and comfortable, so her toes stay apart while painting them but, at the same time, causing no discomfort at all.<br />She s quite happy with them so far, and plans to buy another [QUANTITY] for her sister as a gift.]\nR10E9VDROQ6XIP\t2015-08-28\tI have low testosterone and since I started taking this supplement it seems as though my energy levels have increased.<br />I received a free trial bottle for writing this tries.\t[I have low [OTHER] and since I started taking this supplement it seems as though my energy levels have increased.<br />I received a free trial bottle for writing this tries.]\nR10MQ7N2OBKV8J\t2014-06-14\tThis is my families favorite hot sauce. Not the hottest, but very rich and flavorful-which is what I want. It's the only one I use in my Bloody Mary's.\t[This is my families favorite hot sauce. Not the hottest, but very rich and flavorful-which is what I want. It's the only [QUANTITY] I use in my Bloody Mary's.]\nR10NV3V9MAQMPL\t2015-08-26\tWonderful! Exactly what I needed.\t[Wonderful! Exactly what I needed.]\nR10O8E9ZFXMJ7M\t2015-08-26\tI love every Viva Lab product I have tried, and the Cacao Powder is no exception.  I use it every morning in my almond milk with a little honey.  Excellent flavor!\t[I love every [ORGANIZATION] product I have tried, and the Cacao Powder is no exception.  I use it every [QUANTITY] in my almond milk with a little honey.  Excellent flavor!]\nR10O8ZYRMYD2V3\t2015-08-29\tMy skin is better!\t[My skin is better!]\nR10SKSY1ON6P0D\t2014-06-13\twas not the color I was looking for, I thought the American blue was going t be a darker one but no, has a very turquoise shimmer. I'm going to keep it though I end up ordering the Royal Blue.\t[was not the color I was looking for, I thought the [OTHER] blue was going t be a darker one but no, has a very turquoise shimmer. I'm going to keep it though I end up ordering the Royal Blue.]\n"
          },
          {
            "type": "TEXT",
            "data": "Fail to run sql command: SELECT \n    *\nFROM\n    redact_entities_view\nORDER BY\n    review_id\nLIMIT\n    10\n"
          },
          {
            "type": "ANGULAR",
            "data": "<div class='container ng-scope' style='padding-left:0px;padding-right:0px;'>\n    <div class='panel panel-danger'>\n        <div class='panel-heading' ng-click='isOpen=!isOpen' ng-init='isOpen=false' style=\"cursor:pointer\">\n            <div class='plainTextContainer' style='font-weight:bolder'><i class=\"fa fa-caret-right fa-fw\" style=\"padding-right:7px;transition:all 0.3s;{{isOpen?'transform:rotate(90deg);transform-origin:25% 45%':''}}\"></i>Job was cancelled.</div>\n        </div>\n        <div class='panel-collapse' uib-collapse='!isOpen'>\n            <div class='text' style='max-height:300px;overflow:auto;padding:10px'>java.io.IOException: Fail to run stream sql job\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:172)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:105)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInnerSelect(FlinkStreamSqlInterpreter.java:89)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callSelect(FlinkSqlInterrpeter.java:503)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callCommand(FlinkSqlInterrpeter.java:266)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.runSqlList(FlinkSqlInterrpeter.java:160)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.internalInterpret(FlinkSqlInterrpeter.java:112)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:47)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:852)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:744)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.util.concurrent.ExecutionException: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 5a2451759b9f08e3dd0e60344bb90e79)\n\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)\n\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)\n\tat org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1719)\n\tat org.apache.flink.table.planner.delegation.ExecutorBase.execute(ExecutorBase.java:52)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1214)\n\tat org.apache.zeppelin.flink.sql.AbstractStreamSqlJob.run(AbstractStreamSqlJob.java:161)\n\t... 16 more\nCaused by: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 5a2451759b9f08e3dd0e60344bb90e79)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$getJobExecutionResult$6(ClusterClientJobClientAdapter.java:116)\n\tat java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)\n\tat org.apache.flink.client.program.rest.RestClusterClient.lambda$pollResourceAsync$22(RestClusterClient.java:602)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)\n\tat org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:309)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:610)\n\tat java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1085)\n\tat java.base/java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:478)\n\t... 3 more\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:149)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$getJobExecutionResult$6(ClusterClientJobClientAdapter.java:114)\n\t... 18 more\n</div>\n        </div>\n    </div>\n</div>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "/flinkdashboard/#/job/5a2451759b9f08e3dd0e60344bb90e79",
              "$$hashKey": "object:5027"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1635317245768_1439557464",
      "id": "paragraph_1634849473190_212976388",
      "dateCreated": "2021-10-27T06:47:25+0000",
      "dateStarted": "2021-10-27T07:36:29+0000",
      "dateFinished": "2021-10-27T07:37:02+0000",
      "status": "ABORT",
      "$$hashKey": "object:2800"
    },
    {
      "title": "#3 : Prepare destination table for sending redacted entity results to S3 bucket",
      "text": "%flink.ssql(type=update)\n\nDROP TABLE IF EXISTS amazon_reviews_entities_redacted;\n\nCREATE TABLE amazon_reviews_entities_redacted (\n    review_id STRING,\n    review_date STRING,\n    review_body STRING,\n    redacted_entities ARRAY<STRING>\n)\nPARTITIONED BY (review_date) \nWITH (\n    'connector'='filesystem',\n    'path'='s3://amazon-reviews-bucket-91ff95a0/data/amazon_reviews_entities_redacted/',\n    'format'='json'\n);",
      "user": "anonymous",
      "dateUpdated": "2021-10-27T07:42:40+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Table has been dropped.\nTable has been created.\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1635317245769_1536222124",
      "id": "paragraph_1634849525959_93086420",
      "dateCreated": "2021-10-27T06:47:25+0000",
      "dateStarted": "2021-10-27T07:37:08+0000",
      "dateFinished": "2021-10-27T07:37:09+0000",
      "status": "FINISHED",
      "$$hashKey": "object:2801"
    },
    {
      "title": "#4 : Send redacted entities to destination S3 bucket",
      "text": "%flink.ssql(type=update, parallelism=1)\n\nINSERT INTO \n    amazon_reviews_entities_redacted\nSELECT \n    *\nFROM\n    redact_entities_view\n;",
      "user": "anonymous",
      "dateUpdated": "2021-10-27T07:37:12+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sql",
        "fontSize": 9,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "Fail to run sql command: INSERT INTO \n    amazon_reviews_entities_redacted\nSELECT \n    *\nFROM\n    redact_entities_view\n"
          },
          {
            "type": "ANGULAR",
            "data": "<div class='container ng-scope' style='padding-left:0px;padding-right:0px;'>\n    <div class='panel panel-danger'>\n        <div class='panel-heading' ng-click='isOpen=!isOpen' ng-init='isOpen=false' style=\"cursor:pointer\">\n            <div class='plainTextContainer' style='font-weight:bolder'><i class=\"fa fa-caret-right fa-fw\" style=\"padding-right:7px;transition:all 0.3s;{{isOpen?'transform:rotate(90deg);transform-origin:25% 45%':''}}\"></i>SerializedThrowable: Client execution did not complete before the specified timeout configuration: 5000 millis</div>\n        </div>\n        <div class='panel-collapse' uib-collapse='!isOpen'>\n            <div class='text' style='max-height:300px;overflow:auto;padding:10px'>java.io.IOException: java.util.concurrent.ExecutionException: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 3dc4f53a4450434774a4c2b49ff1b86d)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callInsertInto(FlinkSqlInterrpeter.java:538)\n\tat org.apache.zeppelin.flink.FlinkStreamSqlInterpreter.callInsertInto(FlinkStreamSqlInterpreter.java:97)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callCommand(FlinkSqlInterrpeter.java:273)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.runSqlList(FlinkSqlInterrpeter.java:160)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.internalInterpret(FlinkSqlInterrpeter.java:112)\n\tat org.apache.zeppelin.interpreter.AbstractInterpreter.interpret(AbstractInterpreter.java:47)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:110)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:852)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:744)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.ParallelScheduler.lambda$runJobInScheduler$0(ParallelScheduler.java:46)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.util.concurrent.ExecutionException: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 3dc4f53a4450434774a4c2b49ff1b86d)\n\tat java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)\n\tat java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1999)\n\tat org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1719)\n\tat org.apache.flink.table.planner.delegation.ExecutorBase.execute(ExecutorBase.java:52)\n\tat org.apache.flink.table.api.internal.TableEnvironmentImpl.execute(TableEnvironmentImpl.java:1214)\n\tat org.apache.zeppelin.flink.FlinkSqlInterrpeter.callInsertInto(FlinkSqlInterrpeter.java:532)\n\t... 14 more\nCaused by: org.apache.flink.client.program.ProgramInvocationException: Job failed (JobID: 3dc4f53a4450434774a4c2b49ff1b86d)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$getJobExecutionResult$6(ClusterClientJobClientAdapter.java:116)\n\tat java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:642)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)\n\tat org.apache.flink.client.program.rest.RestClusterClient.lambda$pollResourceAsync$22(RestClusterClient.java:602)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2073)\n\tat org.apache.flink.runtime.concurrent.FutureUtils.lambda$retryOperationWithDelay$8(FutureUtils.java:309)\n\tat java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:859)\n\tat java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:837)\n\tat java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)\n\tat java.base/java.util.concurrent.CompletableFuture.postFire(CompletableFuture.java:610)\n\tat java.base/java.util.concurrent.CompletableFuture$UniCompose.tryFire(CompletableFuture.java:1085)\n\tat java.base/java.util.concurrent.CompletableFuture$Completion.run(CompletableFuture.java:478)\n\t... 3 more\nCaused by: org.apache.flink.runtime.client.JobExecutionException: Job execution failed.\n\tat org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:147)\n\tat org.apache.flink.client.deployment.ClusterClientJobClientAdapter.lambda$getJobExecutionResult$6(ClusterClientJobClientAdapter.java:114)\n\t... 18 more\nCaused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:116)\n\tat org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:78)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:198)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.maybeHandleTaskFailure(DefaultScheduler.java:191)\n\tat org.apache.flink.runtime.scheduler.DefaultScheduler.updateTaskExecutionStateInternal(DefaultScheduler.java:185)\n\tat org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:520)\n\tat org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:397)\n\tat jdk.internal.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:284)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:199)\n\tat org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:74)\n\tat org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:152)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:26)\n\tat akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:21)\n\tat scala.PartialFunction.applyOrElse(PartialFunction.scala:123)\n\tat scala.PartialFunction.applyOrElse$(PartialFunction.scala:122)\n\tat akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:21)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:171)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172)\n\tat akka.actor.Actor.aroundReceive(Actor.scala:517)\n\tat akka.actor.Actor.aroundReceive$(Actor.scala:515)\n\tat akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:225)\n\tat akka.actor.ActorCell.receiveMessage(ActorCell.scala:592)\n\tat akka.actor.ActorCell.invoke(ActorCell.scala:561)\n\tat akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258)\n\tat akka.dispatch.Mailbox.run(Mailbox.scala:225)\n\tat akka.dispatch.Mailbox.exec(Mailbox.scala:235)\n\tat akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\nCaused by: software.amazon.awssdk.core.exception.ApiCallTimeoutException: Client execution did not complete before the specified timeout configuration: 5000 millis\n\tat software.amazon.awssdk.core.exception.ApiCallTimeoutException$BuilderImpl.build(ApiCallTimeoutException.java:88)\n\tat software.amazon.awssdk.core.exception.ApiCallTimeoutException.create(ApiCallTimeoutException.java:38)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.generateApiCallTimeoutException(ApiCallTimeoutTrackingStage.java:147)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.handleInterruptedException(ApiCallTimeoutTrackingStage.java:139)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.translatePipelineException(ApiCallTimeoutTrackingStage.java:107)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:62)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallTimeoutTrackingStage.execute(ApiCallTimeoutTrackingStage.java:42)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:48)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ApiCallMetricCollectionStage.execute(ApiCallMetricCollectionStage.java:31)\n\tat software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\n\tat software.amazon.awssdk.core.internal.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:206)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:37)\n\tat software.amazon.awssdk.core.internal.http.pipeline.stages.ExecutionFailureExceptionReportingStage.execute(ExecutionFailureExceptionReportingStage.java:26)\n\tat software.amazon.awssdk.core.internal.http.AmazonSyncHttpClient$RequestExecutionBuilderImpl.execute(AmazonSyncHttpClient.java:193)\n\tat software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.invoke(BaseSyncClientHandler.java:133)\n\tat software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.doExecute(BaseSyncClientHandler.java:159)\n\tat software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.lambda$execute$1(BaseSyncClientHandler.java:112)\n\tat software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.measureApiCallSuccess(BaseSyncClientHandler.java:167)\n\tat software.amazon.awssdk.core.internal.handler.BaseSyncClientHandler.execute(BaseSyncClientHandler.java:94)\n\tat software.amazon.awssdk.core.client.handler.SdkSyncClientHandler.execute(SdkSyncClientHandler.java:45)\n\tat software.amazon.awssdk.awscore.client.handler.AwsSyncClientHandler.execute(AwsSyncClientHandler.java:55)\n\tat software.amazon.awssdk.services.comprehend.DefaultComprehendClient.detectEntities(DefaultComprehendClient.java:1823)\n\tat com.amazonaws.kinesis.udf.textanalytics.TextAnalyticsUDFHandler.detect_entities(TextAnalyticsUDFHandler.java:226)\n\tat com.amazonaws.kinesis.udf.textanalytics.TextAnalyticsUDFHandler.redact_entities(TextAnalyticsUDFHandler.java:213)\n\tat $line65.$read$$iw$$iw$TextAnalyticsUDF.eval(<console>:67)\n\tat StreamExecCalc$2376.processElement(Unknown Source)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:717)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:692)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:672)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:52)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:30)\n\tat org.apache.flink.table.runtime.operators.wmassigners.WatermarkAssignerOperator.processElement(WatermarkAssignerOperator.java:123)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:717)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:692)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:672)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:52)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:30)\n\tat StreamExecCalc$2329.processElement(Unknown Source)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.pushToOperator(OperatorChain.java:717)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:692)\n\tat org.apache.flink.streaming.runtime.tasks.OperatorChain$CopyingChainingOutput.collect(OperatorChain.java:672)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:52)\n\tat org.apache.flink.streaming.api.operators.CountingOutput.collect(CountingOutput.java:30)\n\tat org.apache.flink.streaming.api.operators.StreamSourceContexts$ManualWatermarkContext.processAndCollectWithTimestamp(StreamSourceContexts.java:310)\n\tat org.apache.flink.streaming.api.operators.StreamSourceContexts$WatermarkContext.collectWithTimestamp(StreamSourceContexts.java:409)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher.emitRecordAndUpdateState(KinesisDataFetcher.java:946)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher.access$000(KinesisDataFetcher.java:108)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher$AsyncKinesisRecordEmitter.emit(KinesisDataFetcher.java:329)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher$SyncKinesisRecordEmitter$1.put(KinesisDataFetcher.java:346)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher$SyncKinesisRecordEmitter$1.put(KinesisDataFetcher.java:343)\n\tat software.amazon.kinesis.connectors.flink.internals.KinesisDataFetcher.emitRecordAndUpdateState(KinesisDataFetcher.java:930)\n\tat software.amazon.kinesis.connectors.flink.internals.ShardConsumer.deserializeRecordForCollectionAndUpdateState(ShardConsumer.java:194)\n\tat software.amazon.kinesis.connectors.flink.internals.ShardConsumer.lambda$run$0(ShardConsumer.java:120)\n\tat software.amazon.kinesis.connectors.flink.internals.publisher.polling.PollingRecordPublisher.run(PollingRecordPublisher.java:115)\n\tat software.amazon.kinesis.connectors.flink.internals.publisher.polling.PollingRecordPublisher.run(PollingRecordPublisher.java:102)\n\tat software.amazon.kinesis.connectors.flink.internals.ShardConsumer.run(ShardConsumer.java:112)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n</div>\n        </div>\n    </div>\n</div>\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "/flinkdashboard/#/job/3dc4f53a4450434774a4c2b49ff1b86d",
              "$$hashKey": "object:5020"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1635317245769_1465343496",
      "id": "paragraph_1634849570328_2131254336",
      "dateCreated": "2021-10-27T06:47:25+0000",
      "dateStarted": "2021-10-27T07:37:12+0000",
      "dateFinished": "2021-10-27T07:38:50+0000",
      "status": "ERROR",
      "$$hashKey": "object:2802"
    },
    {
      "text": "%flink.ssql\n",
      "user": "anonymous",
      "dateUpdated": "2021-10-27T07:14:27+0000",
      "progress": 0,
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1635318867728_326987706",
      "id": "paragraph_1635318867728_326987706",
      "dateCreated": "2021-10-27T07:14:27+0000",
      "status": "READY",
      "$$hashKey": "object:2803"
    }
  ],
  "name": "5-redact-entities-notebook",
  "id": "2GMT52EVG",
  "defaultInterpreterGroup": "flink",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/5-redact-entities-notebook"
}